{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2645,
     "status": "ok",
     "timestamp": 1670217390639,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "O3SkvYOdzU1I",
    "outputId": "81f463ce-8b27-41d5-87f4-435f72596253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from scipy.stats import ortho_group\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda')\n",
    "#torch.cuda.get_device_name(device)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1670217390640,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "TBQzoYyfVGpV"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0],[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670217390640,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "wCaL1M7a1f5v"
   },
   "outputs": [],
   "source": [
    "path0='./'\n",
    "pathAE='./'\n",
    "path='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1315,
     "status": "ok",
     "timestamp": 1670217391947,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "hutjey8mXz9l"
   },
   "outputs": [],
   "source": [
    "dataset_MNIST = MNIST(root=path0, download=True, transform=transform, train=True)\n",
    "dataset_FMNIST = FashionMNIST(root=path0, download=True, transform=transform, train=True)\n",
    "dataset_MNIST_test = MNIST(root=path0, download=True, transform=transform, train=False)\n",
    "dataset_FMNIST_test = FashionMNIST(root=path0, download=True, transform=transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1670217391948,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "zDUI3V1L1oP2"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        self.e = nn.Sequential(\n",
    "            nn.Linear(3*3*32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "\n",
    "        self.d = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, 3*3*32)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.dcnn = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.e(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.d(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.dcnn(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1670217391948,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "uQGaU7egwS_5"
   },
   "outputs": [],
   "source": [
    "class TwoModal(Dataset):\n",
    "    def __init__(self, data1, data2, idx=None):\n",
    "        self.d1 = torch.empty((0, 28, 28), device=device)\n",
    "        self.d2 = torch.empty((0, 28, 28), device=device)\n",
    "        self.t1 = torch.empty((0, ), device=device)\n",
    "        if idx is None:\n",
    "            idx = np.arange(np.min((len(data1), len(data2))))\n",
    "\n",
    "        for i in range(10):\n",
    "            idx1 = (data1.targets[idx] == i)\n",
    "            idx2 = (data2.targets[idx] == i)\n",
    "            label_count = np.min([idx1.sum().numpy(), idx2.sum().numpy()])\n",
    "            data1_c = data1.data[idx][idx1][:label_count]\n",
    "            data2_c = data2.data[idx][idx2][:label_count]\n",
    "            self.t1 = torch.cat((self.t1, torch.full((label_count, ), i)))\n",
    "            self.d1 = torch.cat((self.d1, data1_c))\n",
    "            self.d2 = torch.cat((self.d2, data2_c))\n",
    "        self.t2 = torch.clone(self.t1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return self.d1[idx], self.d2[idx], self.t1[idx], self.t2[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ttf1aBW5vAj8"
   },
   "source": [
    "# Train semi-supervised CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1670217391949,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "j2RM9Fp4u5QH"
   },
   "outputs": [],
   "source": [
    "AE_MNIST = torch.load(pathAE+'AE_MNIST')\n",
    "AE_FMNIST = torch.load(pathAE+'AE_FMNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1670217392153,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "RljpPGBixm8w"
   },
   "outputs": [],
   "source": [
    "n = 500\n",
    "N = 60000 - 2*n\n",
    "v = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670217392154,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "fQY6KIKTVMwR"
   },
   "outputs": [],
   "source": [
    "class TwoModalCompressed(TwoModal):\n",
    "    def __init__(self, data1, data2, idx=None):\n",
    "        super().__init__(data1, data2, idx)\n",
    "        self.d1 = AE_MNIST.encode(self.d1.reshape(-1, 1, 28, 28).float()).detach()\n",
    "        self.d2 = AE_FMNIST.encode(self.d2.reshape(-1, 1, 28, 28).float()).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1670217392155,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "92Km5sJ3XbR1"
   },
   "outputs": [],
   "source": [
    "class DualEncoders(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16)\n",
    "        )\n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16)\n",
    "        )\n",
    "\n",
    "    def sim(self, x1, x2, tau=1):\n",
    "        latent1, latent2 = self.e1(x1), self.e2(x2)\n",
    "        latent1, latent2 = F.normalize(latent1), F.normalize(latent2)\n",
    "        return latent1 @ latent2.T / tau\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_latent = self.e1(x1)\n",
    "        x2_latent = self.e2(x2)\n",
    "        return x1_latent, x2_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12471,
     "status": "ok",
     "timestamp": 1670217404622,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "ldTK9Tpw_T_-"
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(np.arange(60000), 60000)\n",
    "TMC_test = TwoModalCompressed(dataset_MNIST_test, dataset_FMNIST_test)\n",
    "TMC = TwoModalCompressed(dataset_MNIST, dataset_FMNIST, idx[:n])\n",
    "TMC_v = TwoModalCompressed(dataset_MNIST, dataset_FMNIST, idx[n:(n+v)])\n",
    "TMC_u = TwoModalCompressed(dataset_MNIST, dataset_FMNIST, idx[(n+v):(n+v+N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1670217404623,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "LZvpjJUUZhc3"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, TMC_t=TMC_test):\n",
    "    similarity = model.sim(TMC_t.d1.view(TMC_t.d1.size(0), -1), TMC_t.d2.view(TMC_t.d2.size(0), -1), tau=1)\n",
    "    mnist_idx = torch.argmax(similarity, dim=1)\n",
    "    \n",
    "    return similarity, (1 - (TMC_t.t1 != TMC_t.t1[mnist_idx]).sum() / len(TMC_t))#.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1670217404624,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "0bi2aIXZl4zW"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "tau = 1\n",
    "learning_rate = 2e-3\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1670217404624,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "fTUI-TqftGZX"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(TMC, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loss = np.empty((num_epochs,))\n",
    "test_accuracy = np.empty((num_epochs,))\n",
    "\n",
    "MMCL0 = DualEncoders()\n",
    "optimizer = torch.optim.AdamW(MMCL0.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CLIP with paired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61668,
     "status": "ok",
     "timestamp": 1670217466274,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "5GVEHj_FilNV",
    "outputId": "4df76ead-620d-4c11-9c82-d12914524b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] train loss: 2.131e+00, test accuracy 0.169\n",
      "[Epoch 1] train loss: 2.077e+00, test accuracy 0.174\n",
      "[Epoch 2] train loss: 2.017e+00, test accuracy 0.172\n",
      "[Epoch 3] train loss: 1.891e+00, test accuracy 0.205\n",
      "[Epoch 4] train loss: 1.798e+00, test accuracy 0.267\n",
      "[Epoch 5] train loss: 1.938e+00, test accuracy 0.330\n",
      "[Epoch 6] train loss: 1.698e+00, test accuracy 0.362\n",
      "[Epoch 7] train loss: 1.722e+00, test accuracy 0.372\n",
      "[Epoch 8] train loss: 1.769e+00, test accuracy 0.387\n",
      "[Epoch 9] train loss: 1.677e+00, test accuracy 0.398\n",
      "[Epoch 10] train loss: 1.808e+00, test accuracy 0.396\n",
      "[Epoch 11] train loss: 1.745e+00, test accuracy 0.406\n",
      "[Epoch 12] train loss: 1.708e+00, test accuracy 0.423\n",
      "[Epoch 13] train loss: 1.823e+00, test accuracy 0.440\n",
      "[Epoch 14] train loss: 1.799e+00, test accuracy 0.472\n",
      "[Epoch 15] train loss: 1.645e+00, test accuracy 0.464\n",
      "[Epoch 16] train loss: 1.670e+00, test accuracy 0.486\n",
      "[Epoch 17] train loss: 1.636e+00, test accuracy 0.500\n",
      "[Epoch 18] train loss: 1.610e+00, test accuracy 0.485\n",
      "[Epoch 19] train loss: 1.730e+00, test accuracy 0.503\n",
      "[Epoch 20] train loss: 1.692e+00, test accuracy 0.502\n",
      "[Epoch 21] train loss: 1.578e+00, test accuracy 0.506\n",
      "[Epoch 22] train loss: 1.749e+00, test accuracy 0.519\n",
      "[Epoch 23] train loss: 1.600e+00, test accuracy 0.522\n",
      "[Epoch 24] train loss: 1.565e+00, test accuracy 0.521\n",
      "[Epoch 25] train loss: 1.565e+00, test accuracy 0.538\n",
      "[Epoch 26] train loss: 1.562e+00, test accuracy 0.533\n",
      "[Epoch 27] train loss: 1.665e+00, test accuracy 0.536\n",
      "[Epoch 28] train loss: 1.583e+00, test accuracy 0.536\n",
      "[Epoch 29] train loss: 1.791e+00, test accuracy 0.552\n",
      "[Epoch 30] train loss: 1.681e+00, test accuracy 0.552\n",
      "[Epoch 31] train loss: 1.615e+00, test accuracy 0.543\n",
      "[Epoch 32] train loss: 1.998e+00, test accuracy 0.562\n",
      "[Epoch 33] train loss: 1.575e+00, test accuracy 0.551\n",
      "[Epoch 34] train loss: 1.786e+00, test accuracy 0.547\n",
      "[Epoch 35] train loss: 1.649e+00, test accuracy 0.545\n",
      "[Epoch 36] train loss: 1.597e+00, test accuracy 0.545\n",
      "[Epoch 37] train loss: 1.579e+00, test accuracy 0.546\n",
      "[Epoch 38] train loss: 1.475e+00, test accuracy 0.553\n",
      "[Epoch 39] train loss: 1.726e+00, test accuracy 0.559\n",
      "[Epoch 40] train loss: 1.665e+00, test accuracy 0.553\n",
      "[Epoch 41] train loss: 1.603e+00, test accuracy 0.555\n",
      "[Epoch 42] train loss: 1.770e+00, test accuracy 0.558\n",
      "[Epoch 43] train loss: 1.520e+00, test accuracy 0.545\n",
      "[Epoch 44] train loss: 1.582e+00, test accuracy 0.552\n",
      "[Epoch 45] train loss: 1.575e+00, test accuracy 0.561\n",
      "[Epoch 46] train loss: 1.743e+00, test accuracy 0.566\n",
      "[Epoch 47] train loss: 1.590e+00, test accuracy 0.552\n",
      "[Epoch 48] train loss: 1.638e+00, test accuracy 0.556\n",
      "[Epoch 49] train loss: 1.659e+00, test accuracy 0.561\n",
      "[Epoch 50] train loss: 1.789e+00, test accuracy 0.562\n",
      "[Epoch 51] train loss: 1.601e+00, test accuracy 0.559\n",
      "[Epoch 52] train loss: 1.612e+00, test accuracy 0.560\n",
      "[Epoch 53] train loss: 1.681e+00, test accuracy 0.561\n",
      "[Epoch 54] train loss: 1.508e+00, test accuracy 0.568\n",
      "[Epoch 55] train loss: 1.690e+00, test accuracy 0.580\n",
      "[Epoch 56] train loss: 1.484e+00, test accuracy 0.567\n",
      "[Epoch 57] train loss: 1.750e+00, test accuracy 0.569\n",
      "[Epoch 58] train loss: 1.565e+00, test accuracy 0.583\n",
      "[Epoch 59] train loss: 1.724e+00, test accuracy 0.578\n",
      "[Epoch 60] train loss: 1.551e+00, test accuracy 0.579\n",
      "[Epoch 61] train loss: 1.579e+00, test accuracy 0.575\n",
      "[Epoch 62] train loss: 1.562e+00, test accuracy 0.583\n",
      "[Epoch 63] train loss: 1.555e+00, test accuracy 0.577\n",
      "[Epoch 64] train loss: 1.633e+00, test accuracy 0.577\n",
      "[Epoch 65] train loss: 1.531e+00, test accuracy 0.589\n",
      "[Epoch 66] train loss: 1.650e+00, test accuracy 0.575\n",
      "[Epoch 67] train loss: 1.486e+00, test accuracy 0.562\n",
      "[Epoch 68] train loss: 1.505e+00, test accuracy 0.568\n",
      "[Epoch 69] train loss: 1.584e+00, test accuracy 0.578\n",
      "[Epoch 70] train loss: 1.611e+00, test accuracy 0.563\n",
      "[Epoch 71] train loss: 1.581e+00, test accuracy 0.567\n",
      "[Epoch 72] train loss: 1.761e+00, test accuracy 0.562\n",
      "[Epoch 73] train loss: 1.582e+00, test accuracy 0.572\n",
      "[Epoch 74] train loss: 1.571e+00, test accuracy 0.587\n",
      "[Epoch 75] train loss: 1.683e+00, test accuracy 0.569\n",
      "[Epoch 76] train loss: 1.874e+00, test accuracy 0.582\n",
      "[Epoch 77] train loss: 1.694e+00, test accuracy 0.580\n",
      "[Epoch 78] train loss: 1.660e+00, test accuracy 0.573\n",
      "[Epoch 79] train loss: 1.658e+00, test accuracy 0.558\n",
      "[Epoch 80] train loss: 1.634e+00, test accuracy 0.584\n",
      "[Epoch 81] train loss: 1.608e+00, test accuracy 0.577\n",
      "[Epoch 82] train loss: 1.518e+00, test accuracy 0.572\n",
      "[Epoch 83] train loss: 1.504e+00, test accuracy 0.582\n",
      "[Epoch 84] train loss: 1.532e+00, test accuracy 0.561\n",
      "[Epoch 85] train loss: 1.783e+00, test accuracy 0.569\n",
      "[Epoch 86] train loss: 1.531e+00, test accuracy 0.564\n",
      "[Epoch 87] train loss: 1.627e+00, test accuracy 0.570\n",
      "[Epoch 88] train loss: 1.586e+00, test accuracy 0.574\n",
      "[Epoch 89] train loss: 1.559e+00, test accuracy 0.582\n",
      "[Epoch 90] train loss: 1.556e+00, test accuracy 0.555\n",
      "[Epoch 91] train loss: 1.581e+00, test accuracy 0.571\n",
      "[Epoch 92] train loss: 1.545e+00, test accuracy 0.577\n",
      "[Epoch 93] train loss: 1.579e+00, test accuracy 0.545\n",
      "[Epoch 94] train loss: 1.491e+00, test accuracy 0.576\n",
      "[Epoch 95] train loss: 1.552e+00, test accuracy 0.578\n",
      "[Epoch 96] train loss: 1.485e+00, test accuracy 0.581\n",
      "[Epoch 97] train loss: 1.597e+00, test accuracy 0.562\n",
      "[Epoch 98] train loss: 1.574e+00, test accuracy 0.554\n",
      "[Epoch 99] train loss: 1.529e+00, test accuracy 0.580\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        mnist, fmnist, _, _ = data\n",
    "        mnist = mnist.view(mnist.size(0), -1)\n",
    "        fmnist = fmnist.view(fmnist.size(0), -1)\n",
    "        \n",
    "        logits = MMCL0.sim(mnist, fmnist, tau=tau)\n",
    "\n",
    "        ## CLIP loss function\n",
    "        loss1 = - torch.diag(logits).sum() + torch.log(torch.exp(logits).sum(axis=1)).sum()\n",
    "        loss2 = - torch.diag(logits).sum() + torch.log(torch.exp(logits).sum(axis=0)).sum()\n",
    "\n",
    "        loss = (loss1 + loss2) / 2 / len(mnist)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    accuracy = get_accuracy(MMCL0)[1]\n",
    "    print(f\"[Epoch {epoch}] train loss: {loss:.3e}, test accuracy {accuracy:.3f}\")\n",
    "    train_loss[epoch] = loss.detach().numpy()\n",
    "    test_accuracy[epoch] = accuracy.detach().numpy()\n",
    "\n",
    "torch.save(MMCL0, path+'MMCL0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1670217466275,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "TK8s3mRyeb7n"
   },
   "outputs": [],
   "source": [
    "num_epochs_u = 5\n",
    "loops = 20\n",
    "tau_u = 1\n",
    "learning_rate = 2e-5\n",
    "batch_size_u = 64\n",
    "eta = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1670217466275,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "Ra-mGAYMs5rK"
   },
   "outputs": [],
   "source": [
    "dataloader_u = DataLoader(TMC_u, batch_size=batch_size_u, shuffle=True)\n",
    "\n",
    "repeated = np.empty((num_epochs_u*loops,))\n",
    "#repeated2 = np.empty((num_epochs_u*loops,))\n",
    "train_loss_u = np.empty((num_epochs_u*loops,))\n",
    "test_accuracy_u = np.empty((num_epochs_u*loops,))\n",
    "\n",
    "MMCL = torch.load(path+'MMCL0') # Initialize MMCL model based on MMCL with labeled data\n",
    "optimizer = torch.optim.AdamW(MMCL.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CLIP with unpaired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358987,
     "status": "ok",
     "timestamp": 1670217825252,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "bkAbhf9CAG6L",
    "outputId": "f8627d80-6bfb-4bd6-d556-2b8fdc63c21e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] train loss: 3.467726707458496, test accuracy 0.5908440351486206\n",
      "[Epoch 1] train loss: 3.254164218902588, test accuracy 0.5918658971786499\n",
      "[Epoch 2] train loss: 3.321059226989746, test accuracy 0.5941140651702881\n",
      "[Epoch 3] train loss: 3.2463302612304688, test accuracy 0.5961577892303467\n",
      "[Epoch 4] train loss: 3.2135353088378906, test accuracy 0.6008583307266235\n",
      "[Epoch 0] train loss: 3.3168535232543945, test accuracy 0.6031064987182617\n",
      "[Epoch 1] train loss: 3.2550222873687744, test accuracy 0.6038217544555664\n",
      "[Epoch 2] train loss: 3.243773937225342, test accuracy 0.6032086610794067\n",
      "[Epoch 3] train loss: 3.310218334197998, test accuracy 0.6072961091995239\n",
      "[Epoch 4] train loss: 3.323068380355835, test accuracy 0.6089311242103577\n",
      "[Epoch 0] train loss: 3.2849676609039307, test accuracy 0.6101573705673218\n",
      "[Epoch 1] train loss: 3.2106707096099854, test accuracy 0.6048436164855957\n",
      "[Epoch 2] train loss: 3.338115930557251, test accuracy 0.604230523109436\n",
      "[Epoch 3] train loss: 3.2359700202941895, test accuracy 0.6047414541244507\n",
      "[Epoch 4] train loss: 3.1482796669006348, test accuracy 0.6071939468383789\n",
      "[Epoch 0] train loss: 3.3982534408569336, test accuracy 0.6086245775222778\n",
      "[Epoch 1] train loss: 3.2160868644714355, test accuracy 0.6073983311653137\n",
      "[Epoch 2] train loss: 3.270306348800659, test accuracy 0.6064786314964294\n",
      "[Epoch 3] train loss: 3.190019130706787, test accuracy 0.6094420552253723\n",
      "[Epoch 4] train loss: 3.1796085834503174, test accuracy 0.6070917844772339\n",
      "[Epoch 0] train loss: 3.368748188018799, test accuracy 0.6019824147224426\n",
      "[Epoch 1] train loss: 3.298707962036133, test accuracy 0.6089311242103577\n",
      "[Epoch 2] train loss: 3.34837007522583, test accuracy 0.6124054789543152\n",
      "[Epoch 3] train loss: 3.225637912750244, test accuracy 0.6116901636123657\n",
      "[Epoch 4] train loss: 3.3605480194091797, test accuracy 0.6197628974914551\n",
      "[Epoch 0] train loss: 3.1955795288085938, test accuracy 0.6218066215515137\n",
      "[Epoch 1] train loss: 3.175872802734375, test accuracy 0.6208869814872742\n",
      "[Epoch 2] train loss: 3.159533977508545, test accuracy 0.6178213357925415\n",
      "[Epoch 3] train loss: 3.164503335952759, test accuracy 0.6167994737625122\n",
      "[Epoch 4] train loss: 3.259042263031006, test accuracy 0.6180257797241211\n",
      "[Epoch 0] train loss: 3.187634229660034, test accuracy 0.6179235577583313\n",
      "[Epoch 1] train loss: 3.218475818634033, test accuracy 0.6234416365623474\n",
      "[Epoch 2] train loss: 3.292243003845215, test accuracy 0.6267116069793701\n",
      "[Epoch 3] train loss: 3.2282907962799072, test accuracy 0.6235438585281372\n",
      "[Epoch 4] train loss: 3.127324342727661, test accuracy 0.6260985136032104\n",
      "[Epoch 0] train loss: 3.3031702041625977, test accuracy 0.6273247599601746\n",
      "[Epoch 1] train loss: 3.2665717601776123, test accuracy 0.6275291442871094\n",
      "[Epoch 2] train loss: 3.237184762954712, test accuracy 0.6273247599601746\n",
      "[Epoch 3] train loss: 3.3752408027648926, test accuracy 0.6267116069793701\n",
      "[Epoch 4] train loss: 3.342911958694458, test accuracy 0.6265072822570801\n",
      "[Epoch 0] train loss: 3.1241726875305176, test accuracy 0.6260985136032104\n",
      "[Epoch 1] train loss: 3.2375946044921875, test accuracy 0.6241569519042969\n",
      "[Epoch 2] train loss: 3.2226686477661133, test accuracy 0.6277334690093994\n",
      "[Epoch 3] train loss: 3.2340683937072754, test accuracy 0.6307991147041321\n",
      "[Epoch 4] train loss: 3.2799429893493652, test accuracy 0.6285510063171387\n",
      "[Epoch 0] train loss: 3.134976863861084, test accuracy 0.6341712474822998\n",
      "[Epoch 1] train loss: 3.340437889099121, test accuracy 0.6347844004631042\n",
      "[Epoch 2] train loss: 3.238873243331909, test accuracy 0.6341712474822998\n",
      "[Epoch 3] train loss: 3.2110424041748047, test accuracy 0.6375434398651123\n",
      "[Epoch 4] train loss: 3.2205700874328613, test accuracy 0.6369303464889526\n",
      "[Epoch 0] train loss: 3.23618221282959, test accuracy 0.6389740705490112\n",
      "[Epoch 1] train loss: 3.136763095855713, test accuracy 0.6396893262863159\n",
      "[Epoch 2] train loss: 3.1112499237060547, test accuracy 0.6400980949401855\n",
      "[Epoch 3] train loss: 3.233628273010254, test accuracy 0.6406090259552002\n",
      "[Epoch 4] train loss: 3.2122864723205566, test accuracy 0.6438789963722229\n",
      "[Epoch 0] train loss: 3.092735528945923, test accuracy 0.6357040405273438\n",
      "[Epoch 1] train loss: 3.1141562461853027, test accuracy 0.6335581541061401\n",
      "[Epoch 2] train loss: 3.256002902984619, test accuracy 0.6304925680160522\n",
      "[Epoch 3] train loss: 3.1274619102478027, test accuracy 0.6278356909751892\n",
      "[Epoch 4] train loss: 3.2080812454223633, test accuracy 0.6302881240844727\n",
      "[Epoch 0] train loss: 3.034219264984131, test accuracy 0.6314122080802917\n",
      "[Epoch 1] train loss: 3.2965636253356934, test accuracy 0.6303903460502625\n",
      "[Epoch 2] train loss: 3.1133904457092285, test accuracy 0.6258941292762756\n",
      "[Epoch 3] train loss: 3.249706506729126, test accuracy 0.6260985136032104\n",
      "[Epoch 4] train loss: 3.1118900775909424, test accuracy 0.6330472230911255\n",
      "[Epoch 0] train loss: 3.204197406768799, test accuracy 0.6275291442871094\n",
      "[Epoch 1] train loss: 3.276031017303467, test accuracy 0.6274269223213196\n",
      "[Epoch 2] train loss: 3.1436991691589355, test accuracy 0.6239526271820068\n",
      "[Epoch 3] train loss: 3.1295461654663086, test accuracy 0.6285510063171387\n",
      "[Epoch 4] train loss: 3.1679494380950928, test accuracy 0.625383198261261\n",
      "[Epoch 0] train loss: 3.1868326663970947, test accuracy 0.6228285431861877\n",
      "[Epoch 1] train loss: 3.293822765350342, test accuracy 0.6249744892120361\n",
      "[Epoch 2] train loss: 3.2596969604492188, test accuracy 0.6208869814872742\n",
      "[Epoch 3] train loss: 3.2540688514709473, test accuracy 0.6230329275131226\n",
      "[Epoch 4] train loss: 3.1866302490234375, test accuracy 0.6217044591903687\n",
      "[Epoch 0] train loss: 3.047715425491333, test accuracy 0.6213979125022888\n",
      "[Epoch 1] train loss: 3.097916603088379, test accuracy 0.6240547895431519\n",
      "[Epoch 2] train loss: 3.2503111362457275, test accuracy 0.621193528175354\n",
      "[Epoch 3] train loss: 3.272603988647461, test accuracy 0.6215001344680786\n",
      "[Epoch 4] train loss: 3.1668858528137207, test accuracy 0.6240547895431519\n",
      "[Epoch 0] train loss: 3.199939250946045, test accuracy 0.61945641040802\n",
      "[Epoch 1] train loss: 3.3331809043884277, test accuracy 0.6217044591903687\n",
      "[Epoch 2] train loss: 3.198735237121582, test accuracy 0.6266094446182251\n",
      "[Epoch 3] train loss: 3.1591830253601074, test accuracy 0.6248722672462463\n",
      "[Epoch 4] train loss: 3.197490692138672, test accuracy 0.6223175525665283\n",
      "[Epoch 0] train loss: 3.1990010738372803, test accuracy 0.6177191734313965\n",
      "[Epoch 1] train loss: 3.082181692123413, test accuracy 0.622726321220398\n",
      "[Epoch 2] train loss: 3.148449420928955, test accuracy 0.6199673414230347\n",
      "[Epoch 3] train loss: 3.1898975372314453, test accuracy 0.628142237663269\n",
      "[Epoch 4] train loss: 3.2432239055633545, test accuracy 0.6271203756332397\n",
      "[Epoch 0] train loss: 3.3157920837402344, test accuracy 0.6252809762954712\n",
      "[Epoch 1] train loss: 3.1084089279174805, test accuracy 0.6287553310394287\n",
      "[Epoch 2] train loss: 3.116933822631836, test accuracy 0.6368281245231628\n",
      "[Epoch 3] train loss: 3.062084197998047, test accuracy 0.638156533241272\n",
      "[Epoch 4] train loss: 3.250901460647583, test accuracy 0.6413243412971497\n",
      "[Epoch 0] train loss: 3.168917179107666, test accuracy 0.638054370880127\n",
      "[Epoch 1] train loss: 3.08603572845459, test accuracy 0.6360106468200684\n",
      "[Epoch 2] train loss: 3.238075017929077, test accuracy 0.6396893262863159\n",
      "[Epoch 3] train loss: 3.162170171737671, test accuracy 0.6407111883163452\n",
      "[Epoch 4] train loss: 3.2569282054901123, test accuracy 0.636419415473938\n"
     ]
    }
   ],
   "source": [
    "torch.save(MMCL, path+'MMCL_best')\n",
    "best_validation_accuracy = get_accuracy(MMCL0, TMC_v)[1]\n",
    "for l in range(loops):\n",
    "    MMCL_best = torch.load(path+'MMCL_best') # Load the best MMCL model in history\n",
    "    for epoch in range(num_epochs_u):\n",
    "        c = 0\n",
    "        #c2 = 0\n",
    "        t = 0\n",
    "        #s = 0\n",
    "        for data in dataloader_u:\n",
    "            mnist2d, fmnist2d, t1, t2 = data\n",
    "            mnist = mnist2d.view(mnist2d.size(0), -1)\n",
    "            fmnist = fmnist2d.view(fmnist2d.size(0), -1)\n",
    "            m = len(mnist2d)\n",
    "\n",
    "            logits0 = MMCL_best.sim(mnist, fmnist, tau=tau).detach()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = MMCL.sim(mnist, fmnist, tau=tau)\n",
    "            \n",
    "            idx1 = torch.argmax(logits0, dim=0)\n",
    "            idx2 = torch.argmax(logits0, dim=1)\n",
    "            \n",
    "            logits1d = logits.view(m**2)\n",
    "\n",
    "            v1 = logits1d[idx1 + torch.arange(m)*m]\n",
    "            v2 = logits1d[idx2*m + torch.arange(m)]\n",
    "        \n",
    "            loss1 = - v1.mean() + torch.log(torch.exp(logits).sum(axis=1)).mean()\n",
    "            loss2 = - v2.mean() + torch.log(torch.exp(logits).sum(axis=0)).mean()\n",
    "            loss = (loss1 + loss2) / 2\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            _, counts = np.unique(idx1, return_counts=True)\n",
    "            c += (counts > 1).sum()\n",
    "            t += m\n",
    "            \n",
    "        repeated[epoch+l*num_epochs_u] = c / t\n",
    "        accuracy = get_accuracy(MMCL)[1]\n",
    "        print(f\"[Epoch {epoch}] train loss: {loss}, test accuracy {accuracy}\")\n",
    "        train_loss_u[epoch+l*num_epochs_u] = loss.detach().numpy()\n",
    "        test_accuracy_u[epoch+l*num_epochs_u] = accuracy.detach().numpy()\n",
    "    current_validation_accuracy = get_accuracy(MMCL, TMC_v)[1]\n",
    "    if current_validation_accuracy > best_validation_accuracy * eta:\n",
    "        best_validation_accuracy = current_validation_accuracy\n",
    "        torch.save(MMCL, path+'MMCL_best') # Save the current MMCL model if it's validation accuracy is best in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1670217825253,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "Vo9NTiCPtCHr"
   },
   "outputs": [],
   "source": [
    "train_loss_u_sup = np.empty((num_epochs_u*loops,))\n",
    "test_accuracy_u_sup = np.empty((num_epochs_u*loops,))\n",
    "\n",
    "MMCL1 = torch.load(path+'MMCL0') # Initialize MMCL model based on MMCL with labeled data\n",
    "optimizer = torch.optim.AdamW(MMCL1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train oracle MMCL with the information of association in unpaired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289034,
     "status": "ok",
     "timestamp": 1670218114280,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "UXeB8nycy4B0",
    "outputId": "729aa9ee-6aff-47c2-c417-66a267a24158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] train loss: 3.317e+00, test accuracy 0.603\n",
      "[Epoch 1] train loss: 3.239e+00, test accuracy 0.609\n",
      "[Epoch 2] train loss: 3.197e+00, test accuracy 0.621\n",
      "[Epoch 3] train loss: 3.232e+00, test accuracy 0.622\n",
      "[Epoch 4] train loss: 3.110e+00, test accuracy 0.632\n",
      "[Epoch 5] train loss: 3.174e+00, test accuracy 0.639\n",
      "[Epoch 6] train loss: 3.132e+00, test accuracy 0.645\n",
      "[Epoch 7] train loss: 3.126e+00, test accuracy 0.648\n",
      "[Epoch 8] train loss: 3.158e+00, test accuracy 0.650\n",
      "[Epoch 9] train loss: 3.126e+00, test accuracy 0.650\n",
      "[Epoch 10] train loss: 3.171e+00, test accuracy 0.649\n",
      "[Epoch 11] train loss: 3.160e+00, test accuracy 0.655\n",
      "[Epoch 12] train loss: 3.176e+00, test accuracy 0.658\n",
      "[Epoch 13] train loss: 3.118e+00, test accuracy 0.660\n",
      "[Epoch 14] train loss: 3.154e+00, test accuracy 0.663\n",
      "[Epoch 15] train loss: 3.073e+00, test accuracy 0.663\n",
      "[Epoch 16] train loss: 3.282e+00, test accuracy 0.658\n",
      "[Epoch 17] train loss: 3.142e+00, test accuracy 0.654\n",
      "[Epoch 18] train loss: 3.145e+00, test accuracy 0.656\n",
      "[Epoch 19] train loss: 3.114e+00, test accuracy 0.655\n",
      "[Epoch 20] train loss: 3.149e+00, test accuracy 0.651\n",
      "[Epoch 21] train loss: 3.030e+00, test accuracy 0.653\n",
      "[Epoch 22] train loss: 3.179e+00, test accuracy 0.650\n",
      "[Epoch 23] train loss: 3.083e+00, test accuracy 0.654\n",
      "[Epoch 24] train loss: 3.103e+00, test accuracy 0.653\n",
      "[Epoch 25] train loss: 3.194e+00, test accuracy 0.651\n",
      "[Epoch 26] train loss: 3.062e+00, test accuracy 0.651\n",
      "[Epoch 27] train loss: 3.079e+00, test accuracy 0.655\n",
      "[Epoch 28] train loss: 3.079e+00, test accuracy 0.652\n",
      "[Epoch 29] train loss: 3.090e+00, test accuracy 0.654\n",
      "[Epoch 30] train loss: 3.087e+00, test accuracy 0.651\n",
      "[Epoch 31] train loss: 3.068e+00, test accuracy 0.653\n",
      "[Epoch 32] train loss: 3.181e+00, test accuracy 0.653\n",
      "[Epoch 33] train loss: 3.141e+00, test accuracy 0.655\n",
      "[Epoch 34] train loss: 3.056e+00, test accuracy 0.656\n",
      "[Epoch 35] train loss: 3.139e+00, test accuracy 0.656\n",
      "[Epoch 36] train loss: 3.101e+00, test accuracy 0.658\n",
      "[Epoch 37] train loss: 3.097e+00, test accuracy 0.661\n",
      "[Epoch 38] train loss: 3.160e+00, test accuracy 0.662\n",
      "[Epoch 39] train loss: 3.113e+00, test accuracy 0.662\n",
      "[Epoch 40] train loss: 3.055e+00, test accuracy 0.664\n",
      "[Epoch 41] train loss: 3.109e+00, test accuracy 0.665\n",
      "[Epoch 42] train loss: 3.152e+00, test accuracy 0.665\n",
      "[Epoch 43] train loss: 3.169e+00, test accuracy 0.667\n",
      "[Epoch 44] train loss: 3.151e+00, test accuracy 0.671\n",
      "[Epoch 45] train loss: 3.053e+00, test accuracy 0.672\n",
      "[Epoch 46] train loss: 3.133e+00, test accuracy 0.670\n",
      "[Epoch 47] train loss: 3.038e+00, test accuracy 0.672\n",
      "[Epoch 48] train loss: 3.071e+00, test accuracy 0.673\n",
      "[Epoch 49] train loss: 3.067e+00, test accuracy 0.678\n",
      "[Epoch 50] train loss: 3.053e+00, test accuracy 0.673\n",
      "[Epoch 51] train loss: 3.119e+00, test accuracy 0.674\n",
      "[Epoch 52] train loss: 3.158e+00, test accuracy 0.674\n",
      "[Epoch 53] train loss: 3.123e+00, test accuracy 0.670\n",
      "[Epoch 54] train loss: 3.130e+00, test accuracy 0.672\n",
      "[Epoch 55] train loss: 3.027e+00, test accuracy 0.671\n",
      "[Epoch 56] train loss: 3.012e+00, test accuracy 0.675\n",
      "[Epoch 57] train loss: 3.083e+00, test accuracy 0.672\n",
      "[Epoch 58] train loss: 3.124e+00, test accuracy 0.674\n",
      "[Epoch 59] train loss: 3.152e+00, test accuracy 0.677\n",
      "[Epoch 60] train loss: 3.062e+00, test accuracy 0.677\n",
      "[Epoch 61] train loss: 3.076e+00, test accuracy 0.677\n",
      "[Epoch 62] train loss: 3.117e+00, test accuracy 0.679\n",
      "[Epoch 63] train loss: 3.064e+00, test accuracy 0.678\n",
      "[Epoch 64] train loss: 3.076e+00, test accuracy 0.684\n",
      "[Epoch 65] train loss: 3.105e+00, test accuracy 0.685\n",
      "[Epoch 66] train loss: 3.133e+00, test accuracy 0.692\n",
      "[Epoch 67] train loss: 3.072e+00, test accuracy 0.701\n",
      "[Epoch 68] train loss: 3.024e+00, test accuracy 0.699\n",
      "[Epoch 69] train loss: 3.069e+00, test accuracy 0.696\n",
      "[Epoch 70] train loss: 3.071e+00, test accuracy 0.698\n",
      "[Epoch 71] train loss: 3.108e+00, test accuracy 0.699\n",
      "[Epoch 72] train loss: 3.096e+00, test accuracy 0.695\n",
      "[Epoch 73] train loss: 3.144e+00, test accuracy 0.697\n",
      "[Epoch 74] train loss: 3.102e+00, test accuracy 0.701\n",
      "[Epoch 75] train loss: 3.037e+00, test accuracy 0.702\n",
      "[Epoch 76] train loss: 3.059e+00, test accuracy 0.703\n",
      "[Epoch 77] train loss: 3.111e+00, test accuracy 0.700\n",
      "[Epoch 78] train loss: 3.123e+00, test accuracy 0.706\n",
      "[Epoch 79] train loss: 3.069e+00, test accuracy 0.704\n",
      "[Epoch 80] train loss: 3.032e+00, test accuracy 0.703\n",
      "[Epoch 81] train loss: 3.106e+00, test accuracy 0.704\n",
      "[Epoch 82] train loss: 3.042e+00, test accuracy 0.712\n",
      "[Epoch 83] train loss: 3.091e+00, test accuracy 0.715\n",
      "[Epoch 84] train loss: 3.105e+00, test accuracy 0.718\n",
      "[Epoch 85] train loss: 3.133e+00, test accuracy 0.717\n",
      "[Epoch 86] train loss: 3.089e+00, test accuracy 0.722\n",
      "[Epoch 87] train loss: 3.012e+00, test accuracy 0.717\n",
      "[Epoch 88] train loss: 3.056e+00, test accuracy 0.722\n",
      "[Epoch 89] train loss: 3.013e+00, test accuracy 0.726\n",
      "[Epoch 90] train loss: 3.038e+00, test accuracy 0.723\n",
      "[Epoch 91] train loss: 3.087e+00, test accuracy 0.722\n",
      "[Epoch 92] train loss: 3.023e+00, test accuracy 0.725\n",
      "[Epoch 93] train loss: 3.007e+00, test accuracy 0.723\n",
      "[Epoch 94] train loss: 3.197e+00, test accuracy 0.726\n",
      "[Epoch 95] train loss: 3.073e+00, test accuracy 0.727\n",
      "[Epoch 96] train loss: 3.155e+00, test accuracy 0.721\n",
      "[Epoch 97] train loss: 3.093e+00, test accuracy 0.722\n",
      "[Epoch 98] train loss: 3.067e+00, test accuracy 0.725\n",
      "[Epoch 99] train loss: 3.158e+00, test accuracy 0.720\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs_u*loops):\n",
    "    for data in dataloader_u:\n",
    "        mnist, fmnist, _, _ = data\n",
    "        mnist = mnist.view(mnist.size(0), -1)\n",
    "        fmnist = fmnist.view(fmnist.size(0), -1)\n",
    "        \n",
    "        logits = MMCL1.sim(mnist, fmnist, tau=tau)\n",
    "\n",
    "        ## CLIP loss function\n",
    "        loss1 = - torch.diag(logits).sum() + torch.log(torch.exp(logits).sum(axis=1)).sum()\n",
    "        loss2 = - torch.diag(logits).sum() + torch.log(torch.exp(logits).sum(axis=0)).sum()\n",
    "\n",
    "        loss = (loss1 + loss2) / 2 / len(mnist)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    accuracy = get_accuracy(MMCL1)[1]\n",
    "    print(f\"[Epoch {epoch}] train loss: {loss:.3e}, test accuracy {accuracy:.3f}\")\n",
    "    train_loss_u_sup[epoch] = loss.detach().numpy()\n",
    "    test_accuracy_u_sup[epoch] = accuracy.detach().numpy()\n",
    "\n",
    "torch.save(MMCL1, path+'MMCL1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 2017,
     "status": "ok",
     "timestamp": 1670218116291,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "-VEE2mn0h0Pe",
    "outputId": "c2954a7a-a7a1-41ff-9219-7c7eb8351ffd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(num_epochs), test_accuracy, color=\"gray\")\n",
    "plt.plot(num_epochs+np.arange(num_epochs_u*loops), test_accuracy_u, label=f\"n={n}, N={N}\")\n",
    "plt.plot(num_epochs+np.arange(num_epochs_u*loops), test_accuracy_u_sup, label=f\"n={n}+{N}\")\n",
    "plt.axhline(np.max(test_accuracy), linewidth=0.5, color='black')\n",
    "plt.axhline(np.max(test_accuracy_u), linewidth=0.5, color='black')\n",
    "plt.axhline(np.max(test_accuracy_u_sup), linewidth=0.5, color='black')\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim(0, np.max(np.hstack([test_accuracy, test_accuracy_u, test_accuracy_u_sup]))*1.1)\n",
    "plt.xlim(0, num_epochs+num_epochs_u*loops)\n",
    "plt.vlines(num_epochs, 0, 10)\n",
    "plt.legend()\n",
    "plt.savefig(path+\"Test Accuracy2c\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1670218116292,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "ak2Qcpyh9Jp9"
   },
   "outputs": [],
   "source": [
    "np.save(path+'repeated.npy', repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1670218116292,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "Yvv2x0um9Np7"
   },
   "outputs": [],
   "source": [
    "repeated = np.load(path+'repeated.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1670218116292,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "CaXR76AZO-Pi",
    "outputId": "291b9b8f-ccab-4817-9546-677613af32b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25444010259764854"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1670218116293,
     "user": {
      "displayName": "R N (nswa17)",
      "userId": "08662593655458358501"
     },
     "user_tz": 300
    },
    "id": "zcQc50CmPBpu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPULKhtEa7U75LHjdNoYNei",
   "mount_file_id": "1xlxNxM-hHSpUFZnx3BTut45nUbAwLveP",
   "provenance": [
    {
     "file_id": "1mQaWwYJaPRxU1klLn8kG7-O3RyPuCSmF",
     "timestamp": 1670217237112
    },
    {
     "file_id": "1jd-4KQFsdd-tzFL6psa9orBhi2dAYpNe",
     "timestamp": 1670214746068
    },
    {
     "file_id": "1BypIck6Q_5CyJwSbWL-wEHEjdaWhIdi5",
     "timestamp": 1667526516081
    },
    {
     "file_id": "1KS-gRFY6K6dy08M6S3FTDs_CdiBYTbiP",
     "timestamp": 1667485480938
    },
    {
     "file_id": "11EecUgQ8dSknO22TpETSbFrLdMa8ECNP",
     "timestamp": 1666922526698
    },
    {
     "file_id": "1q7GgLb2_FPZ0DrXmAlwF7FNzkE2MPnwG",
     "timestamp": 1666898851720
    },
    {
     "file_id": "1PnrlgMUQyFCSmUBpN0tS62U4SFOIUTdh",
     "timestamp": 1665252738000
    },
    {
     "file_id": "1qi5DA-tIWHXoaSL8Qp2KM-M_BWqVRlCk",
     "timestamp": 1665179120700
    },
    {
     "file_id": "1DF1c7__2dEGZJ8COTVVtXWCeo2h5rXFb",
     "timestamp": 1665176560333
    },
    {
     "file_id": "1q7YroXckfTwPpSRhtugdlYzIRVsU492f",
     "timestamp": 1664989974661
    },
    {
     "file_id": "19Pl98ucy6AFa2YlLSSJJviyRmB8aqEhF",
     "timestamp": 1664849672715
    },
    {
     "file_id": "19-KABEBG-hQ8EGYiCMx0fe41J5PXfqya",
     "timestamp": 1664830778720
    },
    {
     "file_id": "1xlxNxM-hHSpUFZnx3BTut45nUbAwLveP",
     "timestamp": 1664763982791
    },
    {
     "file_id": "1WTP_wR_lLs2CxgU-Sb5yV2ba-_OhTsg_",
     "timestamp": 1664747122962
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e1e5f778fa21f98eeb13efa704c75cef81f45b7dbc097ac50ce2a4cd235d8cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
